training_epoch_count=180
training_algo=sgd
epoch_count_in_training_dataset=2
weight_decay=0.0001
momentum=0.9
momentum_type=nesterov
batch_size=256
shuffle_block_size=7
learning_rate=0.1
learning_rate_policy=step
step_learning_rate_epochs_and_rates=60:0.1:100:0.01:140:0.001
inference_output_layer_name=NLL
inference_output_layer_name=Accuracy
training_output_layer_name=NLL
training_output_layer_name=Accuracy
training_error_source_layer_name=NLL
